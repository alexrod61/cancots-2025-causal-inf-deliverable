[
  {
    "objectID": "website/slides/slides.html#the-team",
    "href": "website/slides/slides.html#the-team",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "1. The team",
    "text": "1. The team\n\nG. Alexi Rodríguez-Arelis (UBC)\nPhilippe Boileau (McGill University)"
  },
  {
    "objectID": "website/slides/slides.html#why-is-the-topic-important",
    "href": "website/slides/slides.html#why-is-the-topic-important",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "2. Why is the topic important?",
    "text": "2. Why is the topic important?\n\n“The goal of causal inference is to estimate the effect in a population of intervening on one variable, the treatment, on another variable, the outcome.” (Cummiskey et al. 2020)\n\n\n\nIn introductory courses, we must go beyond the usual warning “correlation does not imply causation”\nWhat is the underlying process that is generating the data?"
  },
  {
    "objectID": "website/slides/slides.html#why-is-the-topic-important-1",
    "href": "website/slides/slides.html#why-is-the-topic-important-1",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "2. Why is the topic important?",
    "text": "2. Why is the topic important?\n\n\nCarver et al. (2016) indicate that “students should understand that statistics is a problem-solving and decision making process that is fundamental to scientific inquiry and essential for making sound decisions”\nMost importantly, when drawing causal conclusions on observational data, students should be skeptical (Cummiskey et al. 2020)"
  },
  {
    "objectID": "website/slides/slides.html#initial-list-of-potential-outputs",
    "href": "website/slides/slides.html#initial-list-of-potential-outputs",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "3. Initial list of potential outputs",
    "text": "3. Initial list of potential outputs\n\n\nOutputs are in function of developing an undergraduate course (3rd or 4th-year level) spread across 13 weeks:\n\nOverall structure of course content\nLesson plan\nLearning objectives\n\nTwo initial fundamental pillars: experimentation and quasi-experimentation\nA third and more advanced pillar:  observational studies"
  },
  {
    "objectID": "website/slides/slides.html#potential-overall-structure-of-course-content",
    "href": "website/slides/slides.html#potential-overall-structure-of-course-content",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "4. Potential overall structure of course content",
    "text": "4. Potential overall structure of course content\n\n\nThere are four blocks that start with an introduction to DAGs\nThen, we go from full control to no control on the study treatments\nA stronger emphasis on data science-related applications such as A/B testing"
  },
  {
    "objectID": "website/slides/slides.html#challenges-ahead",
    "href": "website/slides/slides.html#challenges-ahead",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "5. Challenges ahead",
    "text": "5. Challenges ahead\n\n\nIs there room within the course to include Bayesian thinking?\nHow smooth would it be to introduce the fundamentals of causality via DAGs and Bayesian networks? (Lu, Zheng, and and 2023)"
  },
  {
    "objectID": "website/slides/slides.html#challenges-ahead-1",
    "href": "website/slides/slides.html#challenges-ahead-1",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "5. Challenges ahead",
    "text": "5. Challenges ahead\n\n\nWhat are the pros and cons of having regression analysis as a prerequisite?\nHow theoretical should we conceived the course? Lübke et al. (2020) provide a fair simulation-based starting via generative modelling and regression analysis"
  },
  {
    "objectID": "website/slides/slides.html#challenges-ahead-2",
    "href": "website/slides/slides.html#challenges-ahead-2",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "5. Challenges ahead",
    "text": "5. Challenges ahead\n\n\nUsing different textbooks to develop course material such as:\n\n“Causal Inference: What If” by Hernán (2024), a review on causal inference with (i.e., parametric) or without (i.e., non-parametric) models\n“A First Course in Causal Inference” by Ding (2024), a review on randomized and observational studies\n“Causal Inference: The Mixtape” by Cunningham (2021), which provides insights on regression discontinuity for quasi-experimentation"
  },
  {
    "objectID": "website/slides/slides.html#reference-material",
    "href": "website/slides/slides.html#reference-material",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "6. Reference material",
    "text": "6. Reference material\n\n\nCarver, R., M. Everson, J. Gabrosek, N. Horton, R. Lock, M. Mocko, A. Rossman, et al. 2016. Guidelines for Assessment and Instruction in Statistics Education: College Report 2016. American Statistical Association.\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas Clark, and Krista Watts and. 2020. “Causal Inference in Introductory Statistics Courses.” Journal of Statistics Education 28 (1): 2–8. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. Yale University Press. https://mixtape.scunning.com/.\n\n\nDing, P. 2024. A First Course in Causal Inference. Chapman; Hall/CRC. https://doi.org/10.1201/9781003484080.\n\n\nHernán, Miguel A. 2024. Causal Inference: What If. Edited by James M. Robins. Boca Raton.\n\n\nLu, Yonggang, Qiujie Zheng, and Daniel Quinn and. 2023. “Introducing Causal Inference Using Bayesian Networks and Do-Calculus.” Journal of Statistics and Data Science Education 31 (1): 3–17. https://doi.org/10.1080/26939169.2022.2128118.\n\n\nLübke, Karsten, Matthias Gehrke, Jörg Horst, and Gero Szepannek and. 2020. “Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Data.” Journal of Statistics Education 28 (2): 133–39. https://doi.org/10.1080/10691898.2020.1752859."
  },
  {
    "objectID": "website/03-course-roadmap.html",
    "href": "website/03-course-roadmap.html",
    "title": "Course Roadmap",
    "section": "",
    "text": "A core component of this course is what we refer to as the causal inference roadmap. This idea emerged during the group meetings and is based on the work of Petersen and Balzer (2014). Their course, titled Introduction to Causal Inference, originally included seven steps: (1) causal model, (2) counterfactuals and causal effects, (3) observed data, (4) identifiability, (5) estimation problem, (6) estimation, and (7) interpretation. However, we have adapted this structure into eight stages.\n\n\n\nImage by Manfred Steger via Pixabay.\n\n\nNote that the course lesson plan is aligned with the causal inference roadmap, progressing sequentially over thirteen weeks. This progression moves from formulating research questions to final storytelling, incorporating elements such as domain expertise, causal diagrams, counterfactual reasoning, and statistical models along the way.\nThe stages can be briefly described as follows:\n\nResearch Question. Every causal analysis begins with a well-defined research question rooted in domain expertise, ensuring it is scientifically meaningful. This stage often requires iterative refinement with subject-matter collaborators to clarify the exposures, outcomes, confounders, and potential mediators involved.\nCausal Model Representing Existing Knowledge. The next step is to encode existing knowledge using a directed acyclic graph (DAG), ideally informed by literature and expert consultation. The DAG clarifies hypothesized dependencies and guides the identification of an appropriate study design—experimental, quasi-experimental, or observational—based on the underlying data-generating process.\nCounterfactuals and Causal Parameters. Causal inference relies on counterfactual reasoning, typically represented as potential outcomes, such as binary \\(Y(0)\\) versus \\(Y(1)\\). Researchers must determine which function of these counterfactuals, such as the average treatment effect (ATE) or the average treatment effect on the treated (ATT), best addresses the original research question, often formalized through structural causal models.\nDefining a Statistical Model. The causal parameter is then mapped to a statistical parameter, such as a regression coefficient or other estimand. Identifiability assumptions—including no unmeasured confounding and positivity—are essential to ensure that the statistical parameter accurately reflects the causal parameter.\nModel Fitting (Estimation). Researchers estimate causal effects using methods suited to the study design and data, such as inverse probability weighting or G-estimation.\nInterpretation. Estimated effects must be interpreted in light of the causal assumptions made. Sensitivity analyses and model diagnostics help evaluate the plausibility of these assumptions and assess the robustness of the conclusions drawn.\nReporting. Findings should be reported transparently, adhering to scientific guidelines appropriate to the study design. Reporting includes not only point estimates of effects but also interval estimates, assumptions, limitations, and the rationale behind the analytical choices made.\nStorytelling. Finally, the results of causal inference must be presented through a coherent narrative that effectively communicates the significance of the findings to both technical and non-technical audiences. Storytelling emphasizes the importance of the research, the implications of the estimated effects, and how they contribute to scientific or policy discussions.\n\n\n\n\n\nReferences\n\nPetersen, Maya, and Laura Balzer. 2014. “Introduction to Causal Inference.” https://ctml.berkeley.edu/introduction-causal-inference.",
    "crumbs": [
      "Home",
      "Course Roadmap"
    ]
  },
  {
    "objectID": "website/01-intro-slides.html",
    "href": "website/01-intro-slides.html",
    "title": "Introductory Slides",
    "section": "",
    "text": "Image by Manfred Stege via Pixabay.\n\n\nThe following slide deck is from the initial roundtable discussion at CanCOTS for this working group. It introduced the primary team involved in the causal inference topic: G. Alexi Rodríguez-Arelis, Assistant Professor of Teaching at UBC in the Department of Statistics, and Philippe Boileau, Assistant Professor of Biostatistics at McGill University. The discussion covered several key points:\n\nWe presented an argument for the importance of incorporating causal inference into statistics courses, especially at the undergraduate level. We discussed the main goals of causal inference in statistics (Cummiskey et al. 2020) and emphasized the need to move beyond the conventional statement, “correlation does not imply causation.” Moreover, we highlighted the importance of teaching the underlying processes that generate data.\nAs instructors, we must convey to students that statistics encompasses both problem-solving and decision-making skills (Carver et al. 2016).\nWhen deriving causal conclusions from observational studies, we must maintain a level of skepticism.\nWe introduced the directed acyclic graph (DAG) as a necessary tool for exploring causal relationships between different variables in a population or system of interest. We also stressed the importance of involving subject-matter experts in the DAG process.\nThe initial proposed outputs from this working group included developing elements for an undergraduate course (at either the 3rd or 4th-year level) over 13 weeks, which will cover the overall course structure, lesson plans, and learning objectives. The course would initially focus on experimentation and quasi-experimentation while also addressing observational studies as an advanced topic.\nThis initial proposed structure consisted of four blocks, beginning with an introduction to DAGs and progressing through experimentation, quasi-experimentation, and observational studies. This structure was intended to emphasize data science-related applications, such as A/B testing.\nWe identified several challenges that might arise during the development of this deliverable, including the inclusion of the Bayesian paradigm, the necessity of regression analysis as a prerequisite, and balancing theoretical content with simulation-based approaches.\nFinally, we suggested three potential resources for course materials: “Causal Inference: What If” by Hernán (2024), “A First Course in Causal Inference” by Ding (2024), and “Causal Inference: The Mixtape” by Cunningham (2021).\n\n\n\n\n\n\n\nImportant\n\n\n\nSince this was an initial presentation, the ideas in points (5), (6), and (7) were later modified to create the final frequentist deliverable, which is detailed in the course outline, course roadmap, and course lesson plan.\n\n\n\n\n\n\n\n\nReferences\n\nCarver, R., M. Everson, J. Gabrosek, N. Horton, R. Lock, M. Mocko, A. Rossman, et al. 2016. Guidelines for Assessment and Instruction in Statistics Education: College Report 2016. American Statistical Association.\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas Clark, and Krista Watts and. 2020. “Causal Inference in Introductory Statistics Courses.” Journal of Statistics Education 28 (1): 2–8. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. Yale University Press. https://mixtape.scunning.com/.\n\n\nDing, P. 2024. A First Course in Causal Inference. Chapman; Hall/CRC. https://doi.org/10.1201/9781003484080.\n\n\nHernán, Miguel A. 2024. Causal Inference: What If. Edited by James M. Robins. Boca Raton.",
    "crumbs": [
      "Home",
      "Introductory Slides"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Incorporating Causal Inference in Statistics Courses",
    "section": "",
    "text": "Details of CanCOTS 2025 including this working group\n\n\n\n\nEvent: Canadian Conference on Teaching Statistics (CanCOTS) 2025.\nHeld by: Statistical Education Section of the Statistical Society of Canada (SSC).\nDates: Wednesday and Thusday, June 11 and 12, 2025.\nPlace: HEC Montréal, Québec, Canada.\nWorking group’s topic: Incorporating Causal Inference in Statistics Courses\nTeam leader during group work sessions: G. Alexi Rodríguez-Arelis (UBC).\n\n\n\n\n1 About This Website\nThis Quarto website contains the final deliverable from one of the working groups of the first edition of the Canadian Conference on Teaching Statistics (CanCOTS), held in the summer of 2025 at HEC Montréal. CanCOTS is primarily a participant-driven working meeting that follows the format of a curated unconference. In this style of unconference, various working groups focus on priority areas of interest related to educational topics in statistics. All groups are expected to produce concrete deliverables addressing these priority areas, which may include exercise banks, curriculum guidelines, sample learning activities, and assessment items. Each working group has a leader who is responsible for overseeing collaborative efforts and shaping the final deliverable.\n\n\n\nImage by manfredsteger via Pixabay.\n\n\nCanCOTS 2025 began with an initial roundtable discussion that brought all participants together. During this session, each group leader presented their educational topic along with a proposal for the final deliverable. Following these presentations, participants split into smaller working groups based on their interests. During the working group meetings, participants—including the group leaders—discussed and brainstormed ideas to develop the final deliverable. Additionally, a comprehensive list of potential resources was compiled to ensure that the deliverable contains fair and scholarly content.\nCanCOTS 2025 featured six different working groups, each focusing on a specific area of interest. One of these groups prioritized incorporating causal inference into statistics courses. As a result, the final deliverable for this working group was a curriculum guideline for developing a fourth-year undergraduate course in causal inference. At the start of the unconference, the specifics of the final deliverable were outlined as follows:\n\nAn overall course curriculum on causal inference (including lesson plan, learning objectives, and an overall structure of course content) with two fundamental pillars: experimentation and quasi-experimentation. A stretch goal of this working group would be incorporating data science-flavored topics such as A/B testing.\n\nNevertheless, during the group meetings, the specifics of the final deliverable were revised to go beyond experimentation and quasi-experimentation to include observational studies. Additionally, the brainstorming sessions focused more on statistical perspectives rather than a data science approach. As a result, the final deliverable included in this repository has the following specifics:\n\nOur final deliverable is an overall fourth-year undergraduate course curriculum on causal inference (including a limited lesson plan, learning objectives, and an overall structure of the course) based on a general causal inference roadmap of eight stages: (1) research question, (2) causal model representing existing knowledge, (3) counterfactuals and causal parameters, (4) defining a statistical model, (5) model fitting (estimation), (6) interpretation, (7) reporting, and (8) storytelling.\n\nThe above causal inference was inspired on the one used in the course Introduction to Causal Inference by Petersen and Balzer (2014).\n\n\n2 Website Overview\nThis overview illustrates the planning and design materials that shaped the development of this final deliverable. It starts with the initial conceptual framing to a structured roadmap and specific lesson plans:\n\nIntroductory Slides: A preliminary set of slides used at the beginning of CanCOTS, later refined into the final deliverable.\nCourse Outline: A general overview detailing the course rationale, description, general learning goals, intended student audience, delivery format, and assessment criteria with grading breakdown.\nCourse Roadmap: A visual and descriptive representation of the eight key stages that structure the course, each with a concise explanation of its role in the causal inference process.\nCourse Lesson Plan: A targeted, structured guide specifying the instructional flow per week.\n\n\n\n3 Acknowledgements\nWe would like to express our gratitude to Philippe Boileau, Irene Vrbik, and Nicole Babor for their valuable contributions during the workgroup sessions at CanCOTS 2025. Their insights in shaping the initial outline of this deliverable were crucial in establishing a solid foundation for its development. While this final deliverable reflects subsequent additions, their collaboration at the beginning was instrumental in setting the course of the project.\n\n\n4 Use of Large Language Models\nAfter the workgroup sessions at CanCOTS 2025, using a large language model (LLM) like ChatGPT (OpenAI 2025) proved to be moderately useful in brainstorming and organizing learning goals for each lecture, aligning with the plans established during the workgroup sessions. Furthermore, the LLM somehow helped identify scholarly references to consider as potential teaching and learning resources, beyond the textbooks mentioned in the introductory slides. However, it was always necessary to carefully verify and analyze each suggested resource directly from the original source to ensure that none of the references were fabricated by ChatGPT, while also ensuring they were aligned with the course’s content scope.\n\n\n5 License\nThis work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.\n\n\n\n\n\n\nReferences\n\nOpenAI. 2025. “ChatGPT.” https://chat.openai.com/.\n\n\nPetersen, Maya, and Laura Balzer. 2014. “Introduction to Causal Inference.” https://ctml.berkeley.edu/introduction-causal-inference."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Overall References",
    "section": "",
    "text": "Alley, Michael. 2013. The Craft of Scientific Presentations: Critical Steps to Succeed and Critical Errors to Avoid. Springer New York. https://link.springer.com/book/10.1007/978-1-4419-8279-7.\n\n\nAnderson, Lorin W., and David R. Krathwohl, eds. 2001. A Taxonomy for Learning, Teaching, and Assessing. A Revision of Bloom’s Taxonomy of Educational Objectives. 2nd ed. New York: Allyn & Bacon.\n\n\nAngrist, Joshua D., and Alan B. Krueger. 1991. “Does Compulsory School Attendance Affect Schooling and Earnings?” The Quarterly Journal of Economics 106 (4): 979–1014. https://doi.org/10.2307/2937954.\n\n\nArif, Suchinta, and M. Aaron MacNeil. 2022. “Utilizing Causal Diagrams Across Quasi-Experimental Approaches.” Ecosphere 13 (4): e4009. https://doi.org/https://doi.org/10.1002/ecs2.4009.\n\n\nArif, Suchinta, and Melanie Duc Bo Massey. 2023. “Reducing Bias in Experimental Ecology Through Directed Acyclic Graphs.” Ecology and Evolution 13 (3): e9947. https://doi.org/https://doi.org/10.1002/ece3.9947.\n\n\nBaron, Reuben M., and David A. Kenny. 1986. “The Moderator-Mediator Variable Distinction in Social Psychological Research: Conceptual, Strategic, and Statistical Considerations.” Journal of Personality and Social Psychology 51 (6): 1173–82. https://doi.org/10.1037/0022-3514.51.6.1173.\n\n\nBloom, B. S., M. B. Engelhart, E. J. Furst, W. H. Hill, and D. R. Krathwohl. 1956. Taxonomy of Educational Objectives. The Classification of Educational Goals. Handbook 1: Cognitive Domain. New York: Longmans Green.\n\n\nBullock, John G., Donald P. Green, and Shang E. Ha. 2010. “Yes, but What’s the Mechanism? (Don’t Expect an Easy Answer).” Journal of Personality and Social Psychology 98 (4): 550–58. https://doi.org/10.1037/a0018933.\n\n\nCard, David. 1995. “Using Geographic Variation in College Proximity to Estimate the Return to Schooling.” Aspects of Labor Market Behaviour: Essays in Honour of John Vanderkamp, 201–23.\n\n\nCarver, R., M. Everson, J. Gabrosek, N. Horton, R. Lock, M. Mocko, A. Rossman, et al. 2016. Guidelines for Assessment and Instruction in Statistics Education: College Report 2016. American Statistical Association.\n\n\nCelli, Viviana. 2021. “Causal Mediation Analysis in Economics: Objectives, Assumptions, Models.” Journal of Economic Surveys 36 (1): 214–34. https://doi.org/https://doi.org/10.1111/joes.12452.\n\n\nChi, W. E., S. Huang, M. Jeon, E. S. Park, T. Melguizo, and A. Kezar. 2022. “A Practical Guide to Causal Mediation Analysis: Illustration with a Comprehensive College Transition Program and Nonprogram Peer and Faculty Interactions.” Frontiers in Education 7: 886722. https://doi.org/10.3389/feduc.2022.886722.\n\n\nCummiskey, Kevin, Bryan Adams, James Pleuss, Dusty Turner, Nicholas Clark, and Krista Watts and. 2020. “Causal Inference in Introductory Statistics Courses.” Journal of Statistics Education 28 (1): 2–8. https://doi.org/10.1080/10691898.2020.1713936.\n\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. Yale University Press. https://mixtape.scunning.com/.\n\n\nDaniel, Rhian M., Simon N. Cousens, Bianca L. De Stavola, Michael G. Kenward, and Jonathan A. C. Sterne. 2013. “Methods for Dealing with Time-Dependent Confounding.” Statistics in Medicine 32 (9): 1584–1618. https://doi.org/10.1002/sim.5686.\n\n\nDing, P. 2024. A First Course in Causal Inference. Chapman; Hall/CRC. https://doi.org/10.1201/9781003484080.\n\n\nElm, Erik von, Douglas G. Altman, Matthias Egger, Stuart J. Pocock, Peter C. Gøtzsche, Jan P. Vandenbroucke, and STROBE Initiative. 2007. “Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Statement: Guidelines for Reporting Observational Studies.” BMJ 335 (7624): 806–8. https://doi.org/10.1136/bmj.39335.541782.AD.\n\n\nGreifer, Noah. 2025. WeightIt: Weighting for Covariate Balance in Observational Studies. https://CRAN.R-project.org/package=WeightIt.\n\n\nHeiss, Andrew. 2020. “Generating Inverse Probability Weights for Both Binary and Continuous Treatments.” December 1, 2020. https://doi.org/10.59350/1svkc-rkv91.\n\n\nHernán, Miguel A. 2024. Causal Inference: What If. Edited by James M. Robins. Boca Raton.\n\n\nHu, Anning. 2024. Statistical Causal Mediation Analysis with r. Springer Singapore. https://doi.org/10.1007/978-981-97-6398-6.\n\n\nHuntington-Klein, N. 2021. The Effect: An Introduction to Research Design and Causality. CRC Press. https://theeffectbook.net/index.html.\n\n\nImai, Kosuke, Luke Keele, Dustin Tingley, and Teppei Yamamoto. 2010. “Causal Mediation Analysis Using r.” In Advances in Social Science Research Using r, edited by H. D. Vinod. New York: Springer-Verlag.\n\n\nKamath, U., K. Graham, and M. Naylor. 2023. Applied Causal Inference. Amazon Digital Services LLC - Kdp. https://appliedcausalinference.github.io/aci_book/.\n\n\nLoh, Wen Wei, and Dongning Ren. 2023. “A Tutorial on Causal Inference in Longitudinal Data with Time-Varying Confounding Using g-Estimation.” Advances in Methods and Practices in Psychological Science 6 (3). https://doi.org/10.1177/25152459231174029.\n\n\nLu, Yonggang, Qiujie Zheng, and Daniel Quinn and. 2023. “Introducing Causal Inference Using Bayesian Networks and Do-Calculus.” Journal of Statistics and Data Science Education 31 (1): 3–17. https://doi.org/10.1080/26939169.2022.2128118.\n\n\nLübke, Karsten, Matthias Gehrke, Jörg Horst, and Gero Szepannek and. 2020. “Why We Should Teach Causal Inference: Examples in Linear Regression with Simulated Data.” Journal of Statistics Education 28 (2): 133–39. https://doi.org/10.1080/10691898.2020.1752859.\n\n\nManski, Charles F. 2019. “Communicating Uncertainty in Policy Analysis.” Proceedings of the National Academy of Sciences 116: 7634–41. https://doi.org/10.1073/pnas.1722389115.\n\n\nMorgan, Stephen L., and Christopher Winship. 2007. Counterfactuals and Causal Inference: Methods and Principles for Social Research. 1st ed. New York: Cambridge University Press.\n\n\nOpenAI. 2025. “ChatGPT.” https://chat.openai.com/.\n\n\nPetersen, Maya, and Laura Balzer. 2014. “Introduction to Causal Inference.” https://ctml.berkeley.edu/introduction-causal-inference.\n\n\nPoppe, Louise, Johan Steen, Wen Wei Loh, Geert Crombez, Fien De Block, Noortje Jacobs, Peter W. G. Tennant, Jelle Van Cauwenberg, and Annick L. De Paepe. 2025. “How to Develop Causal Directed Acyclic Graphs for Observational Health Research: A Scoping Review.” Health Psychology Review 19 (1): 45–65. https://doi.org/10.1080/17437199.2024.2402809.\n\n\nR Core Team. 2024. “R: A Language and Environment for Statistical Computing.” Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nRich, Ben, Erica E. M. Moodie, David A. Stephens, and Robert W. Platt. 2010. “Model Checking with Residuals for g-Estimation of Optimal Dynamic Treatment Regimes.” The International Journal of Biostatistics 6 (2). https://doi.org/10.2202/1557-4679.1210.\n\n\nRobins, James M., and Sander Greenland. 1992. “Identifiability and Exchangeability for Direct and Indirect Effects.” Epidemiology 3 (2): 143–55. http://www.jstor.org/stable/3702894.\n\n\nRohrer, Julia M. 2018. “Thinking Clearly about Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.\n\n\nRosseel, Yves. 2012. “lavaan: An R Package for Structural Equation Modeling.” Journal of Statistical Software 48 (2): 1–36. https://doi.org/10.18637/jss.v048.i02.\n\n\nSchulz, Kenneth F., Douglas G. Altman, David Moher, and CONSORT Group. 2010. “CONSORT 2010 Statement: Updated Guidelines for Reporting Parallel Group Randomised Trials.” PLoS Medicine 7 (3): e1000251. https://doi.org/10.1371/journal.pmed.1000251.\n\n\nSong, Mingyang, Teresa T. Fung, Frank B. Hu, Walter C. Willett, Valter D. Longo, Andrew T. Chan, and Edward L. Giovannucci. 2016. “Association of Animal and Plant Protein Intake with All-Cause and Cause-Specific Mortality.” JAMA Internal Medicine 176 (10): 1453.\n\n\nSterne, Jonathan A. C., and Kate Tilling. 2002. “G-Estimation of Causal Effects, Allowing for Time-Varying Confounding.” The Stata Journal 2 (2): 164–82. https://doi.org/10.1177/1536867X0200200205.\n\n\nTingley, Dustin, Teppei Yamamoto, Kentaro Hirose, Luke Keele, and Kosuke Imai. 2023. Mediation: Causal Mediation Analysis. CRAN. https://cran.r-project.org/web/packages/mediation/vignettes/mediation.pdf.\n\n\nvan der Wal, Willem M., and Ronald B. Geskus. 2011. “ipw: An R Package for Inverse Probability Weighting.” Journal of Statistical Software 43 (13): 1–23. https://doi.org/10.18637/jss.v043.i13.\n\n\nWallace, Michael P., Erica E. M. Moodie, and David A. Stephens. 2017. “An r Package for g-Estimation of Structural Nested Mean Models.” Epidemiology 28 (2): e18–20. https://doi.org/10.1097/EDE.0000000000000586.\n\n\nWallace, Michael, Erica E M Moodie, David A Stephens, Gabrielle Simoneau, Shannon T. Holloway, and Juliana Schulz. 2025. DTRreg: DTR Estimation and Inference via g-Estimation, Dynamic WOLS, q-Learning, and Dynamic Weighted Survival Modeling (DWSurv). https://CRAN.R-project.org/package=DTRreg.\n\n\nWang, Yafeng, Wentao Huang, Adrienne O’Neil, Yutao Lan, Dagfinn Aune, Wei Wang, Chuanhua Yu, and Xiong Chen. 2020. “Association Between Sleep Duration and Mortality Risk Among Adults with Type 2 Diabetes: A Prospective Cohort Study.” Diabetologia 63 (11): 2292–2304.\n\n\nWood, Beverly L., Megan Mocko, Michelle Everson, Nicholas J. Horton, and Paul Velleman. 2018. “Updated Guidelines, Updated Curriculum: The GAISE College Report and Introductory Statistics for the Modern Student.” CHANCE 31 (2): 53–59. https://doi.org/10.1080/09332480.2018.1467642."
  },
  {
    "objectID": "website/02-course-outline.html",
    "href": "website/02-course-outline.html",
    "title": "Course Outline",
    "section": "",
    "text": "Correlation does not imply causation.\n\nLübke et al. (2020) have indicated that the notion described above can be addressed through an understanding of concepts in causal inference. However, as educators in statistics, we have not fully covered these topics in our introductory courses (Cummiskey et al. 2020). Therefore, we need to consider developing undergraduate courses that focus on teaching these key concepts. The Guidelines for Assessment and Instruction in Statistics (GAISE) state that students should be prepared to handle inquiries that require multivariate thinking (Wood et al. 2018). However, Lübke et al. (2020) point out that modelling multivariate data can be misleading, particularly due to issues like confounding. Consequently, it is crucial for students to begin reflecting more on the data generation process to draw meaningful conclusions. In this context, implementing a course like the one outlined in this deliverable would be a significant step toward achieving this goal.\n\n\n\nImage by Manfred Steger via Pixabay.",
    "crumbs": [
      "Home",
      "Course Outline"
    ]
  },
  {
    "objectID": "website/02-course-outline.html#mandatory",
    "href": "website/02-course-outline.html#mandatory",
    "title": "Course Outline",
    "section": "4.1 Mandatory",
    "text": "4.1 Mandatory\n\nSecond-Year Statistical Inference: This course must provide students with a solid foundation in classical statistical tools such as hypothesis testing and confidence intervals. Familiarity with \\(z\\)-tests, \\(t\\)-tests, and Chi-squared tests would enable students to understand how causal claims are assessed statistically. Exposure to simulation-based methods (such as bootstrapping and permutation tests) will be beneficial, as these resampling techniques help estimate uncertainty when analytic solutions are complex or unavailable.\nSecond or Third-Year Probability Theory: This course would provide a good grasp of probability concepts, including independence, conditional probability, and the properties of random variables. Previous exposure to key probability distributions (e.g., Bernoulli, Binomial, Normal, Exponential) and summary statistics (e.g., means and variances) would support both graphical and potential-outcome-based approaches to causal inference. This background would enable students to reason formally about uncertainty and probabilistic dependencies in causal structures.\nThird-Year Regression Analysis: A solid understanding of ordinary least-squares (OLS) and binary logistic regression would be essential. These skills would allow students to model relationships between variables, which is vital for adjusting confounders or estimating treatment effects. These techniques serve as the analytical foundation for many causal inference methods, including potential outcomes frameworks. A reasonable understanding of modelling assumptions, estimation procedures, and model diagnostics in regression analysis will be expected.",
    "crumbs": [
      "Home",
      "Course Outline"
    ]
  },
  {
    "objectID": "website/02-course-outline.html#co-requisite",
    "href": "website/02-course-outline.html#co-requisite",
    "title": "Course Outline",
    "section": "4.2 Co-requisite",
    "text": "4.2 Co-requisite\n\nFourth-Year Experimental Design: A parallel course in experimental design would offer essential theoretical insights into the gold standard of causal inference: the randomized controlled trial (RCT). Students would gain an understanding of the principles of randomization, blocking, and replication. This co-requisite course also connects to the causal inference discussions on the limitations of RCTs and the challenges involved in applying experimental logic to observational data.",
    "crumbs": [
      "Home",
      "Course Outline"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html",
    "href": "website/04-course-lesson-plan.html",
    "title": "Course Lesson Plan",
    "section": "",
    "text": "Image by manfredsteger via Pixabay.\nThis section of the final deliverable presents a concise thirteen-week lesson plan for a fourth-year undergraduate course in causal inference. The lesson plan is limited in scope due to the following reasons:",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#know-your-research-question-stage-1-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#know-your-research-question-stage-1-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.1 Know your Research Question! (stage 1 in the roadmap)",
    "text": "1.1 Know your Research Question! (stage 1 in the roadmap)\nDuring week 1, the instructor is expected to introduce students to a foundational mindset in causal inference, which will be linked to the course’s inferential roadmap. The primary goal for this week is to help students develop the skill to distinguish between statistical inquiries involving association or causation in scientific research. Additionally, students will be introduced to the causal roadmap, which consists of eight stages: (1) research question, (2) causal model representing knowledge, (3) counterfactuals and causal parameters, (4) defining a statistical model, (5) model fitting (estimation), (6) interpretation, (7) reporting, and (8) storytelling. This roadmap will serve as the main pillar of the course’s learning strategy.\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nFurthermore, students will explore real-world examples to understand that causal inference is not merely an isolated statistical technique for modelling data (such as solely fitting ordinary-least squares or binary logistic regression to a dataset). Instead, it represents a comprehensive thought process about counterfactual outcomes (i.e., potential values of \\(Y\\)) and potential treatment interventions (i.e., potential values of \\(X\\)). By the end of this week, students should be able to comprehend the philosophical and practical differences between asking:\n\nIs \\(X\\) associated with \\(Y\\)?\n\nand\n\nDoes \\(X\\) cause \\(Y\\)?\n\n\n\n\n\n\n\nImportant\n\n\n\nRecognizing the statistical difference between the above two statements is crucial across all scientific disciplines in the practice of causal inference. You can check Cummiskey et al. (2020) and Lübke et al. (2020) for further elaboration on this matter.\n\n\n\n1.1.1 Lecture 1\nBy the end of this lecture, students should be able to:\n\nDescribe what causal inference is along with its usefulness in scientific research (remember level).\nExplain how causation and association differ via practical examples (understand level).\nClassify different types of research questions in terms causation and association (understand level).\nIdentify the components of a causal questions, e.g., treatment, outcome, and population.\n\nThe above goals can be mapped to the following materials:\n\nChapter 2 (Research Questions) from Huntington-Klein (2021) and Chapter 1 (A definition of causal effect) from Hernán (2024) and Roadmap Overview & Roadmap Step 0 - Research Question (Lecture 1a - Why Bother with Causal Inference?) from Petersen and Balzer (2014).\nChapter 1 (Correlation, Association, and the Yule-Simpson Paradox) from Ding (2024) and Roadmap Overview & Roadmap Step 0 - Research Question (Lecture 1b - Causal vs. Statistical inference) from Petersen and Balzer (2014).\nChapter 1 (Introduction - Do Not Confuse Correlation with Causality) from Cunningham (2021) and Roadmap Overview & Roadmap Step 0 - Research Question (Lecture 1c: The Causal Roadmap Steps 0-3) from Petersen and Balzer (2014).\nChapters 2 (Randomized Experiments) and 3 (Observational Studies) from Hernán (2024) and Chapter 2 (Potential Outcomes) from Ding (2024).\n\n\n\n1.1.2 Lecture 2\nBy the end of this lecture, students should be able to:\n\nExplain the steps of the causal inference roadmap (understand level).\nExamine real-life study descriptions to identify whether they pose a causal or association question (analyze level).\nFormulate well-structured causal questions based on a given observational or experimental context. (create level).\nAssess the validity and clarity of causal questions in peer-reviewed studies (evaluate level).\n\nThe above goals can be mapped to the following materials:\n\nRoadmap Overview & Roadmap Step 0 - Research Question (Lecture 1c - The Causal Roadmap) from Petersen and Balzer (2014). Recall that the roadmap for this course is inspired by this reference. Hence, this material can be used as a baseline to introduce our roadmap.\nFor this learning goal, the instructor could provide a summary of the following four published papers (two of which pose causal questions, whereas the other two pose association questions):\n\n\nCausal questions:\n\n“Does Compulsory School Attendance Affect Schooling and Earnings?” from Angrist and Krueger (1991).\n“Using Geographic Variation in College Proximity to Estimate the Return to Schooling” from Card (1995).\n\nAssociation questions:\n\n“Association of Animal and Plant Protein Intake With All-Cause and Cause-Specific Mortality” from Song et al. (2016).\n“Association between Sleep Duration and Mortality among Adults with Type 2 Diabetes: A Prospective Cohort Study” from Wang et al. (2020).\n\n\n\nRoadmap Overview & Roadmap Step 0 - Research Question (Lecture 1c - The Causal Roadmap) from Petersen and Balzer (2014).\nMorgan and Winship (2007) provide a fair list of referenced examples in Chapter 1 (Introduction), specifically in sections 1.3.1 (Broad Examples from Sociology, Economics, and Political Science) and 1.3.2 (Narrow and Specific Examples).",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#using-graphical-models-to-depict-causality-stage-2-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#using-graphical-models-to-depict-causality-stage-2-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.2 Using Graphical Models to Depict Causality (stage 2 in the roadmap)",
    "text": "1.2 Using Graphical Models to Depict Causality (stage 2 in the roadmap)\nDuring week 2, students will have their first exposure to directed acyclic graphs (DAGs). According to the course roadmap, DAGs are graphical models that represent knowledge about causal inquiries, which we are expected to develop in collaboration with subject-matter experts. We will view DAGs as essential tools for visualizing and reasoning about causal relationships.\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nThe week will begin with a formal introduction to DAG syntax and terminology. After that, students will engage in hands-on practice constructing DAGs based on real-world scenarios from various scientific fields. Additionally, we will differentiate between experimental, quasi-experimental, and observational studies to demonstrate how DAGs can help identify assumptions in different study designs. By the end of the week, students should understand why DAGs offer valuable insights into causal logic, which will be beneficial for the subsequent stages of the course roadmap.\n\n1.2.1 Lecture 3\nBy the end of this lecture, students should be able to:\n\nExplain key components of DAGs, including nodes, directed edges, and acyclic structure (understand level).\nIllustrate how DAGs represent causal assumptions and the concept of d-separation (understand level).\nCompare DAGs derived from experimental, quasi-experimental, and observational designs to assess differences in identifiability (analyze level).\nConstruct simple DAGs to represent real-life study scenarios (analyze level).\n\nThe above goals can be mapped to the following materials:\n\nChapter 6 (Graphical Representation of Causal Effects) from Hernán (2024) and Chapter 6 (Causal Diagrams) from Huntington-Klein (2021).\nChapter 6 (Graphical Representation of Causal Effects) from Hernán (2024).\nThe following papers can be used to develop material to address this goal:\n\n\n“How to develop causal directed acyclic graphs for observational health research: a scoping review” by Poppe et al. (2025).\n“Reducing bias in experimental ecology through directed acyclic graphs” by Arif and Massey (2023)\n“Utilizing Causal Diagrams across Quasi-Experimental Approaches” by Arif and MacNeil (2022).\n\n\nChapter 7 (Drawing Causal Diagrams) from Huntington-Klein (2021).\n\n\n\n1.2.2 Lecture 4\nBy the end of this lecture, students should be able to:\n\nCreate DAGs to represent hypothetical causal mechanisms based on subject-matter expertise (create level).\nIdentify common structures in DAGs such as confounding, mediating, backdoor criterion, and colliding paths (analyze level).\nEvaluate the adequacy of DAGs constructed by peers or drawn from published studies, focusing on clarity and underlying assumptions (evaluate level).\nDifferentiate between experimental, quasi-experimental, and observational study designs using DAGs to illustrate assumptions and limitations (understand level).\n\nThe above goals can be mapped to the following materials:\n\nTo address this goal, the students could have hands-on practice with the cases depicted by Morgan and Winship (2007) provide a fair list of referenced examples in Chapter 1 (Introduction), specifically in sections 1.3.1 (Broad Examples from Sociology, Economics, and Political Science) and 1.3.2 (Narrow and Specific Examples).\nChapter 8 (Causal Paths and Closing Back Doors) from Huntington-Klein (2021), Chapter 7 (Confounding) from Hernán (2024), and Chapter 1 (Causal Graphs, Identification, and Models of Causal Exposure) from Morgan and Winship (2007).\nTo address this goal, students are expected to assess the DAGs delivered in goal (1) while applying the concepts addressed in goal (2).\nThe developed material from lecture 3, to address the respective goal (3), can be used to fulfil this goal.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#introduction-to-counterfactuals-stage-3-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#introduction-to-counterfactuals-stage-3-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.3 Introduction to Counterfactuals (stage 3 in the roadmap)",
    "text": "1.3 Introduction to Counterfactuals (stage 3 in the roadmap)\nWeek 3 focuses on both the theoretical and practical aspects of counterfactuals. As outlined in the course roadmap, counterfactuals play a crucial role in the entire causal inference process. They are an essential component of the structural causal model (SCM), which is a mathematical framework for illustrating the causal relationships between variables within a given system. This SCM framework will also provide students with computational tools to connect DAGs, discussed in week 2, with counterfactual reasoning.\nThe workflow for this week begins with defining the DAG in the context of a causal inference inquiry within a specific system. Students will then derive a SCM composed of equations that represent the data-generating process for each variable. These equations explicitly illustrate the mechanisms that produce counterfactual outcomes, such as:\n\nWhat would happen to an outcome \\(Y\\) if treatment \\(X\\) were set to a different value?\n\nThis type of inquiry is essential for formulating and interpreting what we refer to as causal parameters, such as the average treatment effect (ATE).\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nBy the end of the week, students are expected to learn how to use code-based simulations in R to apply the logic associated with DAGs, SCMs, and counterfactuals through simple scenarios. They will simulate interventions, explore counterfactuals, and compute causal parameters to address research questions effectively. This process specifically involves examining how potential outcomes arise from different interventions, which allows us to connect our findings back to the DAG and ultimately enables us to produce valid causal claims. It is essential to emphasize to students that our simulated causal parameters must align with the research question(s) established in stage 1 of the roadmap.\n\n1.3.1 Lecture 5\nBy the end of this lecture, students should be able to:\n\nExplain the structure and components of a SCM derived from a DAG (understand level).\nExplain the conceptual link between structural equations and counterfactual outcomes (understand level).\nImplement simple SCMs using code to simulate counterfactual scenarios (apply level).\nClassify the types of causal questions that we can answer from a given SCM and DAG (understand level).\n\nThe above goals can be mapped to the following materials:\n\nChapters 3 (Observational studies) and 5 (Interaction) from Hernán (2024). These chapters offer a comprehensive theoretical content. For in-class material, Roadmap Step 1 - Causal Model (Lecture 2a - Intro to Structural Causal Models), from Petersen and Balzer (2014), is a fair starting point.\nChapter 2 (The Counterfactual Model) from Morgan and Winship (2007); this chapter offers a comprehensive theoretical content. For in-class material, Roadmap Step 1 - Causal Model (Lecture 2b - How SCMs encode causal assumptionss), from Petersen and Balzer (2014), is a fair starting point.\nChapter 4 (Potential Outcomes Causal Model), from Cunningham (2021), provides simple coding examples via R that the instructor could use in their in-class material.\nFor in-class material, Roadmap Step 1 - Causal Model (Lecture 2c - SCMs & Directed Acyclic Graphs), from Petersen and Balzer (2014), is a fair starting point. Moreover, students can continue with the DAGs constructed to address goal (4) from lecture 4 to deliver the corresponding SCMs for the corresponding experimental, quasi-experimental, and observational designs.\n\n\n\n1.3.2 Lecture 6\nBy the end of this lecture, students should be able to:\n\nInterpret counterfactual quantities such as \\(Y(a)\\), the potential outcome under treatment level \\(a\\) (understand level).\nImplement causal parameters (e.g.; ATE or average treatment effect on the treated, ATT) from simulated SCMs using counterfactual logic (apply level).\nIdentify causal parameters with specific scientific research questions (apply level).\nDesign small simulation exercises to test assumptions underlying counterfactual inference (create level).\n\nThe above goals can be mapped to the following materials:\n\nChapters 3 (Observational studies) and 5 (Interaction) from Hernán (2024). These chapters offer a comprehensive theoretical content.\nThere are two potential sources of material we can use to fulfill this goal:\n\n\nThe first one is less technical and it is Chapter 10 - Treatment Effects from Huntington-Klein (2021). If the instructor chooses to use more technical content during class time, this might be an ideal pre-lecture material.\nThe second one is Chapter 4 (Potential Outcomes Causal Model), from Cunningham (2021). This material is more technical.\n\n\nStudents are expected to fulfill this learning goal by using the SCMs delivered in lecture 5 for its corresponding goal (4).\nStudents are expected to continue working with the SCMs from the above goal (3). Now, it is time to code the SCMs delivered from the corresponding experimental, quasi-experimental, and observational designs.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#defining-the-statistical-model-observed-data-and-identifiability-conditions-stage-4-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#defining-the-statistical-model-observed-data-and-identifiability-conditions-stage-4-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.4 Defining the Statistical Model: Observed Data and Identifiability Conditions (stage 4 in the roadmap)",
    "text": "1.4 Defining the Statistical Model: Observed Data and Identifiability Conditions (stage 4 in the roadmap)\nDuring week 4, the instructor is expected to connect the causal model represented by DAGs and SCMs with the corresponding statistical model, with a focus on the identifiability of causal parameters. We start by recalling DAGs as formal representations of causal assumptions. From these DAGs, we construct SCMs, specifying structural equations and endogenous variables that determine counterfactual outcomes. Once the SCM is defined, we analyze how these counterfactuals relate to observed data, emphasizing that only a subset of potential outcomes can be observed.\nA key focus this week is on the spectrum of assumptions in statistical modelling. Parametric models specify a complete probability distribution (for example, ordinary least-squares regression with normally distributed errors), while semi-parametric models relax some of these specifications (like Cox models). Non-parametric models impose minimal assumptions on the functional form, relying solely on the assumptions encoded in the DAG.\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nIn the second half of the week, we define identifiability as the condition under which a causal parameter (such as the ATE) can be expressed as a function of the observed data distribution. Students will learn to utilize d-separation and the back-door criterion as tools to determine when identifiability holds, given the assumptions of no unmeasured confounding and positivity.\nWe will evaluate how each type of statistical model (parametric, semi-parametric, and non-parametric) impacts identifiability. The week will conclude with a comparative discussion across disciplines—such as epidemiology, economics, and statistics—of the various terminologies and conceptual frameworks used to express identifiability conditions. For example, students will explore the relationship between the stable unit treatment value assumption (SUTVA), ignorability in econometrics, and conditional exchangeability in epidemiology. This reflection will help students understand how each domain approaches the identifiability problem through its unique perspective.\n\n1.4.1 Lecture 7\nBy the end of this lecture, students should be able to:\n\nDefine how DAGs and SCMs formalize causal assumptions and determine potential outcomes (remember level).\nConstruct a SCM from a DAG using structural equations and endogenous variables (apply level).\nExamine the relationship between SCMs and observed data, identifying which counterfactuals are observed versus unobserved (analyze level).\nDistinguish between parametric, semi-parametric, and non-parametric statistical models, and their implications for inference (analyze level).\n\nThe above goals can be mapped to the following materials:\n\nRoadmap Step 2 - Counterfactuals & Causal Effects (Lecture 3a - Defining Counterfactuals) from Petersen and Balzer (2014).\nRoadmap Step 2 - Counterfactuals & Causal Effects (Lecture 3b - Deriving Counterfactuals from the Causal Model) and Lecture 3c (Using Counterfactuals to Define Causal Effects) from Petersen and Balzer (2014).\nRoadmap Step 3 - Observed Data (Lecture 5a - Specify the observed data & their link to the causal model and Lecture 5b - Causal models & (in)dependence in the observed data) from Petersen and Balzer (2014).\nRoadmap Step 3 - Observed Data (Lecture 5c - Defining the Statistical Model) from Petersen and Balzer (2014).\n\n\n\n1.4.2 Lecture 8\nBy the end of this lecture, students should be able to:\n\nDetermine whether a causal parameter is identifiable using d-separation and the back-door criterion (evaluate level).\nAssess whether key identifiability conditions—no unmeasured confounding and positivity—hold in study designs (evaluate level).\nCompare how different statistical modelling assumptions (parametric, semi, non-parametric) affect identifiability (understand level).\nBuild a visual map that translates vocabulary across disciplines: SUTVA, ignorability, independence, and exchangeability (create level).\n\n\n\n\n\n\n\nA smooth introduction to identifiability\n\n\n\nChapter 5 - Identification, from Huntington-Klein (2021), offers a smooth introduction to identifiability. It could be used as a pre-reading.\n\n\nThe above goals can be mapped to the following materials:\n\nChapter 3 (Observational Studies) from Hernán (2024). Also, Roadmap Step 4 - Identifiability & Step 5 - Estimation Problem (Lecture 6a - Overview & Intuition for Identifiability and Lecture 6c - The Backdoor Criterion) from Petersen and Balzer (2014).\nRoadmap Step 4 - Identifiability & Step 5 - Estimation Problem (Lecture 6d - The Positivity Assumption) from Petersen and Balzer (2014).\nChapter 11 (Why Model?) from Hernán (2024)\nSection 4.1.5, from Cunningham (2021), provides a detailed elaboration on SUTVA. On the other hand, Kamath, Graham, and Naylor (2023) provide a chapter elaborating on the rest of the terms.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#inverse-probability-weights-stages-4-and-5-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#inverse-probability-weights-stages-4-and-5-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.5 Inverse Probability Weights (stages 4 and 5 in the roadmap)",
    "text": "1.5 Inverse Probability Weights (stages 4 and 5 in the roadmap)\nWeek 5 introduces inverse probability weighting (IPW) as the first method in the course for estimating causal effects from observational data. Building on the identifiability assumptions discussed in week 4, we will now focus on the statistical estimation of causal parameters using weights derived from the treatment assignment mechanism. Students will be guided through both the conceptual rationale and the mathematical foundations of IPW. Specifically, we will explore how IPW constructs a pseudo-population in which treatment is independent of confounders, allowing us to recover the causal estimand from observed data. We will emphasize the critical conditions under which this estimator is valid, particularly the no unmeasured confounding and positivity assumptions.\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nThe week is divided into two sessions. The first session focuses on developing theoretical insights into the IPW framework, while the second session emphasizes practical implementation using R. Students will learn how to estimate weights, assess their quality, and use diagnostic tools to detect violations of key assumptions, such as positivity. We will work with both real and simulated datasets to visualize weight distributions, evaluate performance, and interpret the causal estimates obtained through IPW. This week also provides an opportunity to connect the theoretical framework to concrete software tools, such as the {ipw} (van der Wal and Geskus 2011) and {WeightIt} (Greifer 2025) R packages.\n\n1.5.1 Lecture 9\nBy the end of this lecture, students should be able to:\n\nDefine IPWs and describe their purpose in causal effect estimation (remember level).\nExplain how IPW adjusts for measured confounding by reweighting observations to achieve exchangeability (understand level).\nExamine the assumptions required for valid IPW estimation, including positivity and no unmeasured confounding, and discuss what happens when these assumptions are violated (analyze level).\n\nThe above goals can be mapped to the following materials:\n\nChapter 2 (Randomized Experiments), from Hernán (2024), where Section 2.4 specifically introduces IPW in a non-parametric way. Then, Chapter 12 (IP Weighting and Marginal Estructural Models) elaborates on IPW in a parametric way. Also, Roadmap Step 6B - Estimation with IPW (Lecture 9b - Intro to the IPW Estimator), from Petersen and Balzer (2014), offers a fair starting point for in-class material.\nChapter 12 (IP Weighting and Marginal Estructural Models) provides a complete technical elaboration. Moreover, Roadmap Step 6B - Estimation with IPW (Lecture 9b - Intuition and Implementation of IPW), from Petersen and Balzer (2014), offers a fair starting point for in-class material.\nChapter 12 (IP Weighting and Marginal Estructural Models) provides a complete technical elaboration. Furthermore, Roadmap Step 6B - Estimation with IPW (Lecture 9c - Impact of Positivity Violations on Estimator Performance), from Petersen and Balzer (2014), offers a fair starting point for in-class material.\n\n\n\n1.5.2 Lecture 10\nBy the end of this lecture, students should be able to:\n\nUtilize IPW to estimate average treatment effects using regression models in R (apply level).\nCreate a simulated dataset with known treatment effects and counterfactuals to evaluate the performance of IPW under controlled conditions (create level).\nAssess the quality of estimated IP weights by visualizing their distribution, identifying extreme weights, and interpreting ATE sensitivity to such weights (evaluate level).\n\nThe above goals can be mapped to the following materials:\n\nvan der Wal and Geskus (2011) provide an overview of the {ipw} package with general theoretical background on IPW along with examples via real data. Heiss (2020) provides an example via real data to illustrate both the use of {ipw} and {WeightIt}\nvan der Wal and Geskus (2011) provide an simulated example via the package {ipw}.\nRoadmap Step 6B - Estimation with IPW (Lecture 9c - Impact of Positivity Violations on Estimator Performance), from Petersen and Balzer (2014), offers a fair starting point for in-class material. Moreover, they provide a full lab exercise on IPW.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#g-estimation-for-causal-parameters-stages-4-and-5-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#g-estimation-for-causal-parameters-stages-4-and-5-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.6 G-estimation for Causal Parameters (stages 4 and 5 in the roadmap)",
    "text": "1.6 G-estimation for Causal Parameters (stages 4 and 5 in the roadmap)\nWeek 6 introduces students to G-estimation methods for identifying and estimating causal parameters. This builds directly on the counterfactual framework and the potential outcomes approach developed in previous weeks. G-estimation enables us to estimate causal effects in the presence of time-varying confounders. Students will learn the intuition behind G-estimation and its conceptual connection to structural nested models (SNMs).\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nThis week’s lectures will integrate statistical theory, identification strategies, and applied estimation using R. First, students will learn about the formulation of G-estimation and how it differs from IPW. Next, students will simulate longitudinal data, implement G-estimation in R, and assess the performance of these models in accurately estimating causal parameters. The week will conclude with a discussion on model diagnostics for G-estimation.\n\n1.6.1 Lecture 11\nBy the end of this lecture, students should be able to:\n\nDefine the assumptions required for G-estimation (remember level).\nExplain the differences between G-estimation and IPW (understand level).\nDerive the estimating equations used in G-estimation (apply level).\nAssess when G-estimation is preferable to IPW in terms of finite sample efficiency and bias (evaluate level).\n\n\n\n\n\n\n\nA smooth introduction to G-estimation\n\n\n\nSterne and Tilling (2002) provide a smooth introduction to G-estimation in sections 1 and 2, while the remaining content focuses on its application in Stata. These two initial sections can be used as pre-reading material.\n\n\nThe above goals can be mapped to the following materials:\n\nChapter 14 (G-estimation of structural nested models) from Hernán (2024).\nDaniel et al. (2013) provide a fair biostatistical tutorial that describes both methods, highlighting their relationships and differences. Additionally, they guide the reader on how to choose between them.\nChapter 14 (G-estimation of structural nested models) from Hernán (2024).\nAs in the case of learning goal (2), Daniel et al. (2013) is a fair starting point.\n\n\n\n1.6.2 Lecture 12\nBy the end of this lecture, students should be able to:\n\nImplement G-estimation using different R packages (apply level).\nSimulate longitudinal data under a known data-generating process with time-varying confounding (apply level).\nExecute model diagnostics on G-estimation modelling (apply level).\n\nThe above goals can be mapped to the following materials:\n\nLoh and Ren (2023) provide a tutorial on G-estimation using simulated data via the {lavaan} package. In contrast, M. Wallace et al. (2025) offered a tutorial using the {DTRreg} package, employing both totally simulated data and simulated data inspired by real data.\nFor this learning goal, we can use the work by Loh and Ren (2023) and M. Wallace et al. (2025) Moreover, M. P. Wallace, Moodie, and Stephens (2017) provide an additional simulated example via {DTRreg}.\nRich et al. (2010) provide a fair overview on residual diagnostic plots for G-estimation via simulated and real data.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#causal-mediation-analysis-stages-4-and-5-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#causal-mediation-analysis-stages-4-and-5-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.7 Causal Mediation Analysis (stages 4 and 5 in the roadmap)",
    "text": "1.7 Causal Mediation Analysis (stages 4 and 5 in the roadmap)\nCausal mediation analysis (CMA) allows researchers to go beyond merely estimating total causal effects and to examine the underlying mechanisms through which these effects occur. In week 7, students will learn how to decompose causal effects into direct effects (the part of the treatment effect not explained by a mediator) and indirect effects (the portion transmitted through a mediator). By studying mediation analysis within the course framework, students will gain insights into the challenges of making causal claims about underlying mechanisms. This week will also introduce counterfactual definitions of natural direct and indirect effect. Additionally, students will explore how to implement these concepts in practice by linking theoretical assumptions to the modelling framework used in the {mediation} R package (Imai et al. 2010).\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nThe first lecture covers the conceptual foundations of CMA and formal counterfactual definitions of mediation effects. Students will build a solid theoretical understanding by studying concepts such as average causal mediation effects (ACME), average direct effects (ADE), and the assumptions required for their identification, particularly sequential ignorability. DAGs will illustrate how mediators function within causal systems and highlight common threats, such as unmeasured mediator–outcome confounding.\nThe second lecture shifts focus to the practical estimation and application of mediation analysis using the {mediation} package. Students will learn how to fit mediator and outcome models, extract ACME and ADE estimates, and conduct sensitivity analyses to evaluate robustness against unmeasured confounding. The week will conclude with a short applied exercise where students design and execute their own mediation analysis, integrating theoretical reasoning with empirical estimation.\n\n\n\n\n\n\nA smooth introduction to CMA\n\n\n\nChapter 1 (Introduction and Background) from Hu (2024) provides a brief and clear introduction to CMA in various disciplines of social sciences. It could be used as pre-reading material.\n\n\n\n1.7.1 Lecture 13\nBy the end of this lecture, students should be able to:\n\nExplain the concepts of direct, indirect, and total causal effects, and how they relate to CMA (understand level).\nDescribe the assumptions necessary for causal mediation, particularly sequential ignorability, and illustrate these using causal DAGs (remember level).\nTranslate a causal mediation research question into testable models for mediator and outcome variables, specifying them in a way consistent with the assumptions of causal inference (understand level).\nAssess the plausibility of mediation assumptions in a given applied setting: experimental, quasi-experimental, or observational (evaluate level).\nDemonstrate, with simple examples, how mediator and outcome models can be specified within the {mediation} R package, linking software workflow to the theoretical framework (understand level).\n\nThe above goals can be mapped to the following materials:\n\nChapter 2 (Mediation in the Causal Inference Framework) from Hu (2024), specifically Section 2.2.\nChapter 2 (Mediation in the Causal Inference Framework) from Hu (2024), specifically Section 2.3.\n“The moderator-mediator variable distinction in social psychological research: conceptual, strategic, and statistical considerations” by Baron and Kenny (1986).\nThere are three potential sources of material we can use to fulfill this goal:\n\n\n“Yes, but what’s the mechanism? (don’t expect an easy answer)” from Bullock, Green, and Ha (2010) for experimental studies.\n“Identifiability and Exchangeability for Direct and Indirect Effects” from Robins and Greenland (1992) for observational and experimental studies.\n“Causal mediation analysis in economics: Objectives, assumptions, models” from Celli (2021) for quasi-experimental studies.\n\n\nExamples found in Tingley et al. (2023).\n\n\n\n1.7.2 Lecture 14\nBy the end of this lecture, students should be able to:\n\nUse the {mediation} R package to fit mediator and outcome models, estimate ACME, ADE, and total effects (apply level).\nConduct sensitivity analysis with medsens() in the {mediation} package to examine robustness to unmeasured confounding of the mediator–outcome relation (apply level).\nDesign and implement a mini mediation analysis on a provided dataset, integrating theoretical assumptions, estimation procedures, and interpretation of results (create level).\n\nThe above goals can be mapped to the following materials:\n\nChapter 3 (Estimation of the Causal Mediation Analysis) from Hu (2024).\nChapter 5 (Sensitivity Analysis) from Hu (2024).\nA Practical Guide to Causal Mediation Analysis: Illustration With a Comprehensive College Transition Program and Nonprogram Peer and Faculty Interactions from Chi et al. (2022). This paper provides a step-by-step guide using the {mediation} package with an accessible college transition program dataset.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#interpretation-and-report-stages-6-and-7-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#interpretation-and-report-stages-6-and-7-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.8 Interpretation and report (stages 6 and 7 in the roadmap)",
    "text": "1.8 Interpretation and report (stages 6 and 7 in the roadmap)\nThe causal roadmap does not conclude with the application of any one of the previous estimation methods. Therefore, during week 8, students will shift from point estimation of causal effects to providing corresponding interpretations of those effects alongside the communication of their findings. This communication requires researchers to articulate their modelling assumptions, contextualize the estimation results, and, quite importantly, report the uncertainty associated with these estimates. The instructor is expected to introduce students to the principles of causal interpretation. Special attention will be given to linking statistical evidence with the causal roadmap framework and discussing the limitations of methods in applied contexts.\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nStudents are expected to learn how to translate technical causal findings into narratives suitable for academic papers, policy briefs, or industry reports. The instructor must emphasize how to convey both point estimates and interval estimates (i.e., confidence intervals) along with sensitivity analysis. By the end of this week, students should be prepared to produce causal inference reports that will be used in the following week when they will practice storytelling.\n\n1.8.1 Lecture 15\nBy the end of this lecture, students should be able to:\n\nExplain the distinction between statistical significance, effect size, and causal relevance when presenting findings (understand level).\nInterpret causal effect estimates in the context of research questions, including both point and interval estimates (understand level).\nAssess robustness of causal conclusions by incorporating sensitivity analyses (evaluate level).\n\n\n\n1.8.2 Lecture 16\nBy the end of this lecture, students should be able to:\n\nSummarize causal inference study designs, assumptions, and results in structured reporting formats (understand level).\nOutline visualization techniques to communicate causal results clearly (understand level).\nExplain how a causal inference report is structured in regards to assumptions, identifiability, estimation results, sensitivity analyses, and limitations (understand level).\n\n\n\n1.8.3 Overall Material Mapping\nThis week, we will not map scholarly materials by learning goal. Instead, we will provide a complete set of materials for the entire week:\n\nRoadmap Step 6E - Inference & Step 7 - Interpretation (Lecture 13a - Okay! We have a point estimate; what about a variance estimate?; Lecture 13c - Introduction to the Non-parametric Bootstrap; and Lecture 13d - Interpretation!, from Petersen and Balzer (2014), offers a fair starting point for in-class material. Moreover, they provide lab exercises on point and interval estimation.\nElm et al. (2007) provide a whole checklist on the elements that must be included when reporting results on observational studies in epidemiology. It is part of the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) Initiative.\nOn the other hand, Schulz et al. (2010) provide a whole checklist on the elements that must be included when reporting results on parallel group randomized trials in healthcare. This is the 2010 version of the Consolidated Standards of Reporting Trials (CONSORT) statement.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#storytelling-stage-8-in-the-roadmap",
    "href": "website/04-course-lesson-plan.html#storytelling-stage-8-in-the-roadmap",
    "title": "Course Lesson Plan",
    "section": "1.9 Storytelling (stage 8 in the roadmap)",
    "text": "1.9 Storytelling (stage 8 in the roadmap)\n\n\n\nImage by Manfred Stege via Pixabay.\n\n\nIn week 9, we will focus on the storytelling stage of the course’s roadmap. This involves translating the entire statistical research into a compelling, transparent, and coherent narrative for the relevant stakeholders. We dedicate a full week to this stage because it is essential to emphasize the technical training from the previous stages while also crafting this final narrative for effective communication with our target audience, which might pertain to technical peers or policy stakeholders. Students are expected to learn how to structure their causal analysis by starting with the study’s motivation and research question, followed by the graphical and statistical models, and concluding with interpretable and well-contextualized findings. The primary goal for this week is to teach students how to integrate the inferential process with effective communication skills.\nStudents will work with completed causal analyses, specifically the ones from week 1 in lecture 2, which were used to distinguish between causal and association questions (Angrist and Krueger 1991; Card 1995). Since these real-life studies are comprehensive, students will be tasked with reframing them into well-crafted narratives that balance transparency and audience engagement. On the other hand, the instructor will teach best practices related to data storytelling, scientific writing, and proper DAG elaboration. While the instructor provides instruction and quick examples, students will engage in hands-on practice using one of the two causal analyses mentioned earlier. By the end of the week, students will have a clear understanding of the practical skills needed to narrate a causal analysis from start to finish. This will prepare them for the appraisal and dataset-based projects in the final weeks of the course.\n\n1.9.1 Lecture 17\nBy the end of this lecture, students should be able to:\n\nIdentify the essential components of a causal inference narrative, including motivation, causal question, identification strategy, and interpretation of estimates (apply level).\nDistinguish between statistical reporting and causal storytelling, recognizing where transparency requires explicit methodological framing (analyze level).\nAssess the clarity and persuasiveness of a causal story using predefined rubrics and scholarly criteria (evaluate level).\nCriticize how uncertainty and limitations are communicated in causal narratives (evaluate level).\nAnalyze published studies to determine how methodological rigour is conveyed alongside narrative flow (analyze level).\n\n\n\n1.9.2 Lecture 18\nBy the end of this lecture, students should be able to:\n\nApply the course’s causal roadmap to reorganize an existing causal analysis into a structured story (apply level).\nDevelop graphical and tabular summaries to support and enhance the causal narrative (apply level).\nDesign an outline for a causal inference presentation that balances technical detail and accessibility (create level).\nAdapt a causal inference narrative for distinct audiences (e.g., academic journal, policy brief, public-facing report) while retaining methodological integrity (create level).\n\n\n\n1.9.3 Overall Material Mapping\nFor this week, we will not map scholarly materials by learning goal. Instead, we will divide them into two main sets. The first set of resources, which corresponds to lecture 17, will be helpful for instructors in teaching best practices related to data storytelling, scientific writing, and proper DAG elaboration:\n\nRohrer (2018) provides an adequate framework for explaining key terms related to causal inference, particularly in the context of observational studies. This includes concepts such as DAGs, confounders, colliders, and mediators within a psychology context. Furthermore, they include a helpful example regarding genetic confounding.\nWhile this book does not focus specifically on causal inference storytelling, Alley (2013) presents useful guidelines for oral presentations in science and engineering. The following chapters can be valuable for preparing teaching materials:\n\nChapter 2: Speech - The Words You Say. This chapter offers practical advice on crafting a speech tailored to the intended audience.\nChapter 3: Structure - The Strategy You Choose. This chapter discusses how to effectively structure a speech while balancing its scope and depth. It also provides tips on keeping the audience engaged and addressing any potential biases.\nChapter 4: Visual Aids - Your Supporting Cast. This chapter provides guidelines for creating and delivering effective slides during an oral presentation.\n\nSince causal analyses are often intended for decision-makers in public policy, it is crucial to teach how to communicate uncertainty regarding causal parameter estimation. Manski (2019) documents various practices of uncertainty communication through different examples.\n\nAs previously mentioned for lecture 18, the following papers will be reused to practice storytelling:\n\n“Does Compulsory School Attendance Affect Schooling and Earnings?” from Angrist and Krueger (1991).\n“Using Geographic Variation in College Proximity to Estimate the Return to Schooling” from Card (1995).",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#learning-goals",
    "href": "website/04-course-lesson-plan.html#learning-goals",
    "title": "Course Lesson Plan",
    "section": "2.1 Learning Goals",
    "text": "2.1 Learning Goals\nThe learning goals outlined below ensure that this appraisal project showcases students’ ability to effectively evaluate the strength of published causal research. Additionally, we assess their ability to justify and communicate their analyses to peers, as well as their teamwork skills.\n\n2.1.1 Remember Level\n\nRecall the key stages and assumptions of the causal roadmap.\n\n\n\n2.1.2 Understand Level\n\nSummarize the main research question, design, and estimation approach of the assigned paper.\nExplain the researchers’ reasoning behind the study’s design choices and statistical methods in relation to causal inference principles.\n\n\n\n2.1.3 Apply Level\n\nApply the causal roadmap to systematically evaluate the study’s methodology.\nIdentify the core methodological elements of experimental, quasi-experimental, and observational study designs.\nMake use of course concepts to identify potential sources of bias in the published work.\n\n\n\n2.1.4 Analyze Level\n\nDifferentiate between well-supported causal claims and conclusions that overreach the evidence presented.\nCompare the methodological approach of the assigned study to the principles learned in the course.\n\n\n\n2.1.5 Evaluate Level\n\nCriticize the adequacy of the study’s causal assumptions, identifying any unaddressed confounding, selection bias, or measurement error.\nJudge the robustness of the study’s findings by considering alternative explanations and sensitivity to methodological choices.\n\n\n\n2.1.6 Create Level\n\nDevelop a coherent, well-structured oral presentation that summarizes the critical appraisal.\nFormulate constructive recommendations for how the study could have been improved in design, analysis, and/or interpretation.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#weekly-breakdown",
    "href": "website/04-course-lesson-plan.html#weekly-breakdown",
    "title": "Course Lesson Plan",
    "section": "2.2 Weekly Breakdown",
    "text": "2.2 Weekly Breakdown\nThe first lecture of week 10 will introduce the appraisal project. It will include a clear explanation of the objectives, expectations, and evaluation criteria. During this lecture, the instructor will assign each team a different published research paper. These papers will be selected to represent a variety of causal designs, including experimental, quasi-experimental, and observational studies. Each paper will be sufficiently documented to facilitate meaningful team-based analysis. The instructor will provide a detailed background for each paper to ensure that teams can conduct an informed analysis. Teams will be responsible for dissecting the methodological approach, assessing validity, and evaluating the study’s adherence to principles of causal inference.\nFollowing this introduction, teams will spend the rest of week 10 working collaboratively on their assigned paper. This will involve mapping the study’s design, data, and analysis onto the course’s causal roadmap, identifying strengths and weaknesses, and critiquing methodological choices. Students will be expected to approach matters such as confounding, identifiability, and the data modelling assumptions. The emphasis will be on deep engagement with the chosen study rather than superficial summary.\nIn week 11, teams will give in-class presentations on their appraisals. Each team will present its findings in a structured format, emphasizing the alignment (or misalignment) of the published work with the causal roadmap. The presentation should also address the implications for the robustness and interpretability of the reported causal claims. Presentations will include both technical critiques and clear communication of methodological insights, fostering peer-to-peer learning as students compare and contrast different approaches across various papers. Since the presentation is the only deliverable for this appraisal project, teams will be encouraged to focus on clarity, depth of reasoning, and the effective use of visual and statistical evidence to support their assessments.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#learning-goals-1",
    "href": "website/04-course-lesson-plan.html#learning-goals-1",
    "title": "Course Lesson Plan",
    "section": "3.1 Learning Goals",
    "text": "3.1 Learning Goals\nThe learning goals outlined below ensure that this final project demonstrates students’ mastery of the complete causal inference process. Additionally, we evaluate their ability to justify and communicate modelling assumptions, as well as their capacity to collaborate effectively in designing, executing, and defending a real-world causal analysis.\n\n3.1.1 Remember Level\n\nRecall the eight stages of the causal roadmap\nDefine the role of the above eight stages when conducting a causal analysis.\n\n\n\n3.1.2 Understand Level\n\nSummarize the background of the provided dataset and describe how it supports causal inference.\nInterpret the assumptions (e.g., exchangeability, positivity, etc.) underlying the chosen estimation approach for the causal analysis.\n\n\n\n3.1.3 Apply Level\n\nApply the causal roadmap to formulate a clearly defined causal research question based on the provided dataset.\nConstruct a comprehensive DAG that represents the assumed causal structure and justifies the variables to condition on.\nUtilize estimation procedures via R (e.g., IPW, G-estimation, or CMA), which should be consistent with the outlined causal model.\n\n\n\n3.1.4 Analyze Level\n\nExamine the links between underlying assumptions, model choices, and causal conclusions to assess coherence and validity.\n\n\n\n3.1.5 Evaluate Level\n\nAssess the quality of model diagnostics used to evaluate the robustness of causal estimates.\nCriticize the strengths and limitations of the team’s analytic approach and provide a concise assessment of the causal claim.\n\n\n\n3.1.6 Create Level\n\nDevelop a comprehensive and coherent written report that includes the causal question, methodology, assumptions, and findings in an accessible way to both technical and non-technical audiences.\nCompile the roadmap stages into a reproducible causal workflow, including code, visualizations, and documentation, to support transparency and reproduciblity.\nDesign an executive summary or policy brief from the report tailored to a relevant stakeholder or decision-maker.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  },
  {
    "objectID": "website/04-course-lesson-plan.html#weekly-breakdown-1",
    "href": "website/04-course-lesson-plan.html#weekly-breakdown-1",
    "title": "Course Lesson Plan",
    "section": "3.2 Weekly Breakdown",
    "text": "3.2 Weekly Breakdown\nAt the beginning of week 12 (specifically, the first in-class session), teams will be introduced to a publicly available dataset, accompanied by a detailed background presentation from the instructor. This presentation will include relevant contextual, scientific, and structural information necessary to support a wide range of causal inquiries. Teams will be tasked with formulating their own causal research questions (rather than being provided with predefined inquiries) and must justify their formulations based on the data and background information provided. This approach allows teams to leverage the first stage of the roadmap effectively.\nStarting with the second session of week 12, teams will conduct their causal analyses using the dataset in conjunction with the eight-stage causal roadmap. They will be expected to iteratively apply concepts such as graphical modelling with DAGs, SCMs, counterfactual definition, identifiability assessment, and appropriate estimation methods, along with interpretation and storytelling. Note that we will use the same dataset for all teams, allowing instructors to evaluate different methodological approaches and assumptions reflected in each team’s application of the roadmap.\nThe last two sessions of the course (i.e., week 13) will be structured as open lab-style working sessions, where teams can receive feedback from the instructor. This feedback will provide an opportunity for teams to refine their analyses and coordinate roles and responsibilities. The final deliverable for this causal analysis will be a comprehensive team report that documents each step of the roadmap, the rationale behind the team’s decisions, diagnostic evaluations, limitations, and their final estimated causal effects.\n\n\n\n\n\n\nA note on the lack of final exam in this course\n\n\n\nIt is important to note that the above final deliverable will replace a traditional final exam. Additionally, we want to emphasize that this capstone project is a team-based effort that highlights collaborative causal analysis, as is commonly practiced in both academic and applied research settings.",
    "crumbs": [
      "Home",
      "Course Lesson Plan"
    ]
  }
]